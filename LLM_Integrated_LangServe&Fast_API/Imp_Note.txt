Note:
*** Instill capability to build Serverless API(i.e Hosting API on cloud that leverage Scalable servers [pay on demand] by AWS LAMBDA,AZURE FUNCTIONS GOOGLE CLOUD FUNCTIONS ), by Configuring Endpoints,passing secret manager keys(i.e env Api tokens) ****

DIRECTION W.R.T. CODE FUNCTIONALITY-
client.py--------------------------------------------->>API(constructed using FastAAPI& routes leveraging LANGSERVE)<<--------------------------------------------------------api_app.py
    (direction specifies code built to fetch from API on passing User I/P)          (code direction to place the routes (with corresponding endpoints -created for access to models for given I/P) to the API )

cpt=ChatPromptTemplate
1. Implementation involves execution of llm models on both
    - Promp_template_1 with execution of its LLm Chains_1--ex-: LLMChain(llm=llm1,prompt=prompt1)
    - ChatPromptTemplate with  Chain operators-- ex-: (Chat_prompt1 | llms_1 | outputparsser)

2. 2 WAYS TO IMPLEMENT ChatPromptTemplate
 - 1) cpt.from_messages 
   --a. BaseMessage format cpt.from_messages([HumanMessage(content="Provide overview of llm"),SystemMessage(content="Behave as Ai Sonnet assistant")])
   --b. MIXED_MESSAGE format cpt.from_messages(("human","provide information on {key}"),SystemMessage(content="Behave as Ai Sonnet assistant"))
   --c. homogenous tuple format cpt.from_messages(("human or user","Provide information on {key}"),('system',"behave as Ai Sonnet assistant")
 
 - 2) cpt.from_templates (BY DEFAULT ASSUMES FROM HUMAN) 
    --  cpt.from_templates("provide information on {key}")

3. ORDER MATTERS dUring implementaion of CHAIN OPERATORS
    i.e Chat_prompt1 | llms_1 | outputparsser

4. Unable to extract text from front end to that of api_app.py in the context of usage of ChatPromptTemplate.from_messages([HumanMessage(content="about{key}"),SystemMessage(content=Behave as AI Assistant")])
*****DOESNT WORK FOR INVOKE OR [ ~~FIND AN ALTERNTAIVE~~ (iTS NATURE OF THE ABOVE SYNTAX -VERIFIED EXECUTION IN doC & TEXT SUMMARIZATION REPO)] SINCE IT DOESNT EXTRACT THE KEY TEXT1 OR TEXT2 FROM FRONT-END *******chatprompt1=ChatPromptTemplate.from_messages([SystemMessage(content="Behave as a Ai assistant to answer."),HumanMessage(content="Provide a brief overview about {text1} in 1 paragraphs")])
***But does work for Base message in MIXED_MESSAGE FORMAT WHERE HumanMessage() IS REPLACED WITH ("human", overview of {key}) & SystemMessage SAME AS BASE MESSAGE)
