Customize a prompt
Models from the Ollama library can be customized with a prompt. For example, to customize the llama3 model:

In terminal(optional if model is already loaded in your machine, thereby skip it & mv ahead with custom model creation )------------ollama pull llama3
In vscode _current working directory---------Create a Modelfile:
copy below  code to the Modelfile created in current working directory
code:-
________________________________________________________________________________
FROM llama2

# set the temperature to 1 [higher is more creative, lower is more coherent]
PARAMETER temperature 1

# set the system message
SYSTEM """
You are Mario from Super Mario Bros. Answer as Mario, the assistant, only.
"""

________________________________________________________________________________
Next, create a new custom model name and run the model:

In terminal ------------------------------ollama create mario -f ./Modelfile
In terminal (optional since you would be using it in your llm1=Ollama(model="san_custom_mod"))-------------------------------ollama run mario
Hello! It's your friend Mario.

NOTE: 
- YOU CAN DIRECTLY REMOVE THE CUSTOM MODEL USING OLLAMA -RM CUSTOM MODEL_NAME(make sure to close the current.py file before deleting) OR DIRECTLY FROM THE MANIFEST FOLDER IN .OLLAMA FOLDER.
- if temperature isto be modified change temp value in ModelFile & re run  ollama create custom_model_name_tempValue_for_easeofsearch -f ./Modelfile.
- validate installation of models in local  with OLLAM cmds for list, remove, create etc.